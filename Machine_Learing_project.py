# -*- coding: utf-8 -*-
"""PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z0d_aaDzYsFP-oKKzw3wdjNjNXlwofD_
"""

# Commented out IPython magic to ensure Python compatibility.
#Importing Liabraries
import pandas as pd
import pylab as pl
import numpy as np
from math import sqrt

import matplotlib.pyplot as plt

# %matplotlib inline


#ML Liabraries
import itertools
import random
import scipy
import pylab

# Data Loading preprocessing
df = pd.read_csv('Vehicle_Emissions_Data.csv')
df.head()

df.size

df.info()

df.isnull().sum() #for number of null values

# there are missing values present in dataset, so replacing the missing values by mean
engine_size_mean = df['Engine_Size'].mean()
co2_emissions_mean = df['CO2_Emissions'].mean()

# Replace missing values with the mean
df['Engine_Size'].fillna(engine_size_mean, inplace=True)
df['CO2_Emissions'].fillna(co2_emissions_mean, inplace=True)

df.info()

# Obtain metadata of given dataset

df.describe()

print(df.head())


# Variable Creation
# Creating a new variable 'Engine_Size_Category' based on 'Engine_Size'
def categorize_engine_size(engine_size):
    if engine_size < 2.0:
        return 'Small'
    elif 2.0 <= engine_size < 3.0:
        return 'Medium'
    else:
        return 'Large'

df['Engine_Size_Category'] = df['Engine_Size'].apply(categorize_engine_size)

# Display the head of the transformed and created dataset
print("\nHead of the dataset after transformation and creation:")
print(df.head())

# Select only numeric columns for correlation analysis
numeric_columns = df.select_dtypes(include=['int64', 'float64'])

# Compute the correlation matrix
correlation_matrix = numeric_columns.corr()

# Print the correlation matrix
print("\nCorrelation Matrix:")
print(correlation_matrix)

#histogram of CO2 emissions.
plt.hist(df['CO2_Emissions'])
plt.xlabel('CO2 Emissions')
plt.show()

plt.hist(df['Engine_Size'])
plt.xlabel('Engine_Size')
plt.show()
plt.hist(df['Transmission'])
plt.xlabel('Transmission')
plt.show()
plt.hist(df['Smog_Level'])
plt.xlabel('Smog_Level')
plt.show()
plt.hist(df['Fuel_Consumption_comb(L/100km)'])
plt.xlabel('Fuel_Consumption_comb(L/100km)')
plt.show()

df.iloc[28]

import matplotlib.pyplot as plt



# Set up the figure and subplots
plt.figure(figsize=(15, 10))

# Plot for Categorical Feature (Vehicle_Class)
plt.subplot(3, 2, 1)
df['Vehicle_Class'].value_counts().plot(kind='bar', color='skyblue')
plt.title("Vehicle Class")
plt.xlabel("Vehicle Class")
plt.ylabel("Count")

# Plot for Numeric Feature 1 (Engine_Size)
plt.subplot(3, 2, 2)
plt.bar(df["Vehicle_Class"], df["Engine_Size"])
plt.title("Engine Size")
plt.xlabel("Vehicle Class")
plt.ylabel("Engine Size")

# Plot for Numeric Feature 2 (CO2_Emissions)
plt.subplot(3, 2, 3)
plt.bar(df["Vehicle_Class"], df["CO2_Emissions"])
plt.title("CO2 Emissions")
plt.xlabel("Vehicle Class")
plt.ylabel("CO2 Emissions")

# Adjust layout
plt.tight_layout()
plt.show()

df.head()

x = ["Engine_Size", "Cylinders", "Fuel_Consumption_comb(L/100km)", "Smog_Level"]
df1= df
for i in x:
  df1[i] = df[i]/np.abs(df1[i].max())
df.head()

#find outlier for  numeric attributes
plt.boxplot(df1["CO2_Emissions"]);
plt.xlabel("CO2_Emissions")

#detect outlier from CO2_Emissions & replace mean value
q=list(df1["CO2_Emissions"].quantile([0,0.25,0.5,0.75,1]))
q

IQR=q[3] - q[1]
IQR

LIF =q[1] - (1.5*IQR)
LOF =q[1] - (3*IQR)
UIF =q[3] + (1.5*IQR)
UOF =q[3] + (3*IQR)

upper_outlier = list(df1[df1["CO2_Emissions"]>UIF].index)
print(upper_outlier)

x=df1
x_mean=df1["CO2_Emissions"].mean()
df.head()

x.iloc[upper_outlier,10]=x_mean

plt.boxplot(df1["CO2_Emissions"]);

"""# LAB 5

"""

test = df1
test.info()

"""**Lab 6**"""

df.head()

#create train data and test data for development of model

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(df[['CO2_Emissions']], df['Engine_Size'], random_state=0)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("Y_train shape:", Y_train.shape)
print("Y_test shape:", Y_test.shape)

#linear regression model to predict the Engine_size

from sklearn import linear_model as lm

#imported linear model package

Lin_model = lm.LinearRegression()

X_train = np.asanyarray(X_train[['CO2_Emissions']])
Y_train = np.asanyarray(Y_train)

#find optimized relationship between variables
Lin_model.fit (X_train, Y_train)

# the coefficient method
print('coefficients: ', Lin_model.coef_)
print('Intercept: ', Lin_model.intercept_)

#finding predicted price by power
predicted_Engine_Size = Lin_model.predict(X_train)

print("MSE: ", np.mean(np.square(predicted_Engine_Size-Y_train)))

def signmoidal(z):
    return (1/(1+np.exp(-z)))

# z = w0 + w1x
logistic_predicted = signmoidal(predicted_Engine_Size)
logistic_predicted

type(logistic_predicted)
logistic_predicted.shape

df1 = pd.DataFrame(logistic_predicted, columns=["logistic_predicted"])
df1.head()

def fun(p):
    if(p<0.5):
        return 0
    else:
        return 1

#multiple regression / multiple input features

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(df[['CO2_Emissions',"Fuel_Consumption_comb(L/100km)", "Smog_Level"]], df['Engine_Size'], random_state=0)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("Y_train shape:", Y_train.shape)
print("Y_test shape:", Y_test.shape)

from sklearn import linear_model as lm

Lin_model = lm.LinearRegression()

df.head()

from sklearn import linear_model as lm
model = lm.LinearRegression()
Xtrain = np.asanyarray(X_train)
Ytrain = np.asanyarray(Y_train)
model.fit(Xtrain, Ytrain)
Yhat = model.predict(Xtrain)

print(Yhat.shape)

"""# **Logistic Regression**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Assuming your DataFrame is named 'df'

# Select features and target variable
X = df[['Model_Year', 'Engine_Size', 'Cylinders', 'Fuel_Consumption_in_City(L/100 km)',
        'Fuel_Consumption_in_City_Hwy(L/100 km)', 'Fuel_Consumption_comb(L/100km)',
        'CO2_Emissions', 'Smog_Level']]
y = df['Engine_Size_Category']  # Assuming 'Engine_Size_Category' is the target variable

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and fit logistic regression model
logistic_model = LogisticRegression(max_iter=1000)
logistic_model.fit(X_train, y_train)

# Predictions on training set
train_predictions = logistic_model.predict(X_train)

# Predictions on test set
test_predictions = logistic_model.predict(X_test)

# Model evaluation
train_accuracy = accuracy_score(y_train, train_predictions)
test_accuracy = accuracy_score(y_test, test_predictions)

print("Training Accuracy:", train_accuracy)
print("Test Accuracy:", test_accuracy)

# Classification report
print("\nClassification Report:")
print(classification_report(y_test, test_predictions))

"""**Support Vector Machine**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the SVM classifier
svm_classifier = SVC(kernel='linear')

# Train the classifier
svm_classifier.fit(X_train, y_train)

# Make predictions
predictions = svm_classifier.predict(X_test)

# Evaluate the classifier
accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)
print("\nClassification Report:")
print(classification_report(y_test, predictions))